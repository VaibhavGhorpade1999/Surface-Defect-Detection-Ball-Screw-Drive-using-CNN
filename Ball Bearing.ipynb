{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9b4f02c-7883-45f5-944f-75c51b2b5212",
   "metadata": {},
   "source": [
    "# Ball Screw Drive Surface Defect Dataset for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff07b48-2210-4c13-8316-98d769eafba2",
   "metadata": {},
   "source": [
    "## 1. Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa872954-39d2-4985-87f8-ac92ecfe7b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.callbacks import History "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2c5499-c335-46e7-a4cb-dcd8ad3e5d0f",
   "metadata": {},
   "source": [
    "## 2. Importing Image of `N` and `P` Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "259fa313-d97f-4259-8298-3099cb3011fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "path1=r\"D:\\Github\\Ball Bearing Fault Detection\\Data\\testing_data\"\n",
    "cate=[\"N\",\"P\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a572cf9-98ee-448c-a05f-9ecef394870e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_size=200\n",
    "input_image=[]\n",
    "for i in cate:\n",
    "    folders=os.path.join(path1,i)\n",
    "    label=cate.index(i)\n",
    "    for image in os.listdir(folders):\n",
    "        image_path=os.path.join(folders,image)\n",
    "        image_array=cv2.imread(image_path)\n",
    "        image_array=cv2.resize(image_array,(image_size,image_size))\n",
    "        input_image.append([image_array,label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98826218-e239-403d-a6ee-a893545716db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715cf5f1-29c7-4185-836b-43b8716aa0f1",
   "metadata": {},
   "source": [
    "## 3. Randomly Shuffling Image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dae915c-a3b0-4178-b6a8-f68b158c0345",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(input_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d18152f-0344-499a-ac0d-6bb30dbfdfc4",
   "metadata": {},
   "source": [
    "## 4. Splitting into X and Y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "153ee5c1-34f7-493f-b66f-96c96e0fe4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "Y=[]\n",
    "for X_values,labels in input_image:\n",
    "    X.append(X_values)\n",
    "    Y.append(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46b2ec5-004a-4ab3-a687-0f7d16aeb71f",
   "metadata": {},
   "source": [
    "## 5. Normalising the data by dividing the x test and train by max pixel size ==255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6fde28b-9e2b-4c27-a568-1e52c2de7399",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(X)\n",
    "Y=np.array(Y)\n",
    "X=(X/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9799d163-dcd6-4eff-a9df-e6bcd3ad13a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X[0:3000]\n",
    "Y_train=Y[0:3000]\n",
    "X_test=X[3000::]\n",
    "Y_test=Y[3000::]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c269c7-9226-42fd-952b-8d289582d366",
   "metadata": {},
   "source": [
    "## 6. Applying VGG19 Model for deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8228faca-dfe0-40f7-8a8a-1b3abfa9c207",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPool2D,Flatten,Dense,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f93c54e8-bbd6-469d-9801-d7ca5c343257",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Lambda, Flatten, Input\n",
    "from keras.preprocessing  import image\n",
    "from keras.models import Sequential\n",
    "import glob\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a491aa20-4605-45b0-8153-8e09b6733ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "922d5807-f06a-458f-8387-7ba9650d1680",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size= [200 , 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "693290df-5f71-4464-8e27-f37abc591fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 200, 200, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 200, 200, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 200, 200, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 100, 100, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 100, 100, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 100, 100, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 50, 50, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 50, 50, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 50, 50, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 50, 50, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 25, 25, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 25, 25, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 25, 25, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 25, 25, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 12, 12, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg = VGG16(input_shape = image_size +[3], weights = 'imagenet' ,  include_top = False)\n",
    "vgg.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41a79f77-bfff-4307-9348-807d26b896fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg.layers:        \n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebda0589-376f-48ad-b638-9e2016023452",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Flatten()(vgg.output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7388195-77a3-42a1-9f93-4bc1725256a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = Dense(2 , activation = 'sigmoid')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96bbf51e-9c6f-41f0-b6b5-1f05af84f82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(vgg.input,prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39ac4707-4df6-486b-91b3-d1d409ca05f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 200, 200, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 200, 200, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 200, 200, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 100, 100, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 100, 100, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 100, 100, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 50, 50, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 50, 50, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 50, 50, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 50, 50, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 25, 25, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 25, 25, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 25, 25, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 25, 25, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 12, 12, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 18432)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 36866     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,751,554\n",
      "Trainable params: 36,866\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a65b33c6-ddcb-4b37-9520-172a05300bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy',metrics=[\"accuracy\"] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a29cbd1-174b-4151-bc47-6c9955f3e7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "#Y = to_categorical(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ffdf9a6-51f3-4795-bb9b-2a9f439cc8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "94/94 [==============================] - 263s 3s/step - loss: 0.2817 - accuracy: 0.8930\n",
      "Epoch 2/6\n",
      "94/94 [==============================] - 256s 3s/step - loss: 0.1365 - accuracy: 0.9540\n",
      "Epoch 3/6\n",
      "94/94 [==============================] - 253s 3s/step - loss: 0.0933 - accuracy: 0.9687\n",
      "Epoch 4/6\n",
      "94/94 [==============================] - 252s 3s/step - loss: 0.0765 - accuracy: 0.9790\n",
      "Epoch 5/6\n",
      "94/94 [==============================] - 252s 3s/step - loss: 0.0605 - accuracy: 0.9843\n",
      "Epoch 6/6\n",
      "94/94 [==============================] - 255s 3s/step - loss: 0.0465 - accuracy: 0.9887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ce8d009f10>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train,epochs=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d39099-e419-4e38-a16a-45765d95c851",
   "metadata": {},
   "source": [
    "## 7. Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eaec626f-edf7-4a86-9d1e-9bbe49418a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 91s 3s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.20718281e-03, 9.96994257e-01],\n",
       "       [9.76034641e-01, 1.66835394e-02],\n",
       "       [9.54954326e-01, 9.65693220e-02],\n",
       "       ...,\n",
       "       [1.11728255e-02, 9.90088582e-01],\n",
       "       [7.03609476e-05, 9.99927163e-01],\n",
       "       [5.00579514e-02, 9.60115850e-01]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_value=model.predict(X_test)\n",
    "pred_value      #it gives prediction in probabilites for 2 classes for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7740b5f-5a8f-40ec-b5cb-6b92516ddcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_classes=np.argmax(pred_value,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757a3a2d-003d-459e-8135-fe0ea61d1069",
   "metadata": {},
   "source": [
    "## 8. Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d573ffe0-da83-42a4-bfac-11217f2577a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,recall_score,f1_score,precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cee2fe31-2704-4a48-9e29-0c41f8062ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[494,  15],\n",
       "       [ 13, 478]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab=confusion_matrix(Y_test,pred_classes)\n",
    "tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1158592-7d3f-4825-8658-120e4d7a2438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy=accuracy_score(Y_test,pred_classes)*100\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03f7483b-756b-45bb-bf2a-d6839b8e296f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.95740365111561"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision=precision_score(Y_test,pred_classes)*100\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "36187332-615a-459f-a54b-15974c4deda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.35234215885947"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall=recall_score(Y_test,pred_classes)*100\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4dc3dea4-a141-4574-a07e-9cacfe580f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.15447154471545"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_Score=f1_score(Y_test,pred_classes)*100\n",
    "f1_Score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
